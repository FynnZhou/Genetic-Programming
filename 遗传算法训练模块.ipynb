{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:100: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:94: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:131: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:137: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata \n",
    "import pickle\n",
    "\n",
    "from gplearn import genetic\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicTransformer, SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('/data/train_data_pre3.pkl', 'rb') as train_f:\n",
    "    train_data = pickle.load(train_f)\n",
    "# with open('/home/kesci/test_total_data.pkl', 'rb') as test_f:\n",
    "#     test_data = pickle.load(test_f)\n",
    "\n",
    "fields = ['open', 'high', 'low', 'avg', 'pre_close', 'close','volume']\n",
    "# 训练数据\n",
    "X_train = train_data[fields].values\n",
    "y_train = train_data['predict_pct'].values\n",
    "# # 测试数据\n",
    "# X_test = test_data[fields].values\n",
    "# y_test = test_data['predict_pct'].values\n",
    "\n",
    "# 系统自带的函数群\n",
    "\n",
    "\"\"\"\n",
    "Available individual functions are:\n",
    "\n",
    "‘add’ : addition, arity=2.\n",
    "‘sub’ : subtraction, arity=2.\n",
    "‘mul’ : multiplication, arity=2.\n",
    "‘div’ : protected division where a denominator near-zero returns 1., arity=2.\n",
    "‘sqrt’ : protected square root where the absolute value of the argument is used, arity=1.\n",
    "‘log’ : protected log where the absolute value of the argument is used and a near-zero argument returns 0., arity=1.\n",
    "‘abs’ : absolute value, arity=1.\n",
    "‘neg’ : negative, arity=1.\n",
    "‘inv’ : protected inverse where a near-zero argument returns 0., arity=1. \n",
    "‘max’ : maximum, arity=2.\n",
    "‘min’ : minimum, arity=2.\n",
    "‘sin’ : sine (radians), arity=1.\n",
    "‘cos’ : cosine (radians), arity=1.\n",
    "‘tan’ : tangent (radians), arity=1.\n",
    "\"\"\"\n",
    "\n",
    "# init_function = ['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv', 'max', 'min', 'sin', 'cos', 'tan']\n",
    "init_function = ['add', 'sub', 'mul', 'div','sqrt', 'log','inv','sin','max','min']\n",
    "\n",
    "# 自定义函数, make_function函数群\n",
    "\n",
    "def _rolling_rank(data): #第 i 个元素为𝑋𝑖在向量 X 中的分位数\n",
    "    value = rankdata(data)[-1]\n",
    "    return value  #scipy.rankdata 排序\n",
    "\n",
    "def _rolling_prod(data):\n",
    "    return np.prod(data) #所有元素乘积\n",
    "\n",
    "\n",
    "def _delta(data):\n",
    "    value = np.diff(data.flatten())\n",
    "    value = np.append(0, value)\n",
    "    return value\n",
    "\n",
    "def _delay(data): # d 天以前的 X 值\n",
    "    period=1  #当period为正时，默认是axis = 0轴的设定，向下移动\n",
    "    value = pd.Series(data.flatten()).shift(period)\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_sum(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列之和 \n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).sum().tolist())  \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "    #a.flatten  把a降到一维，默认是按横的方向降\n",
    "    #pandas.rolling(window) 以窗口取相邻数据进行计算\n",
    "    \n",
    "def _sma(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列之平均值\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).mean().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _stddev(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列之标准差\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_rank(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列之 分位数\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(10).apply(_rolling_rank).tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _product(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列之 乘积\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(10).apply(_rolling_prod).tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_min(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列中最小值\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).min().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_max(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列中最大值\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).max().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def _rank(data): \n",
    "    value = np.array(pd.Series(data.flatten()).rank().tolist())  #pandas.rank 平均排位\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _scale(data): #scale(X, a) 向量 a*X/sum(abs(X))，a 的缺省值为 1，一般 a 应为正数\n",
    "    k=1\n",
    "    data = pd.Series(data.flatten())\n",
    "    value = data.mul(1).div(np.abs(data).sum()) \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_argmax(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列中最大值出现的位置\n",
    "    window=10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmax) + 1 \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_argmin(data): #第 i 个元素为过去 d 天𝑋𝑖值构成的时序数列中最小值出现的位置\n",
    "    window=10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmin) + 1 \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "##########################################    \n",
    "def _cube(data):\n",
    "    return np.square(data)*data\n",
    "\n",
    "def _square(data):\n",
    "    return np.square(data)\n",
    "    \n",
    "def _corr(data1,data2,n):\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "            \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window  = n[0]\n",
    "\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "            \n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "            \n",
    "# def _stddev(data,n):   \n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "#         try:    \n",
    "#             if n[0] == n[1] and n[1] ==n[2]:\n",
    "#                 window  = int(np.mean(n))\n",
    "                \n",
    "#                 value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "#                 value = np.nan_to_num(value)\n",
    "    \n",
    "#                 return value\n",
    "#             else:\n",
    "#                 return np.zeros(data.shape[0])\n",
    "                \n",
    "#         except:\n",
    "#             return np.zeros(data.shape[0])\n",
    "\n",
    "# make_function函数群\n",
    "delta = make_function(function=_delta, name='delta', arity=1)\n",
    "delay = make_function(function=_delay, name='delay', arity=1)\n",
    "rank = make_function(function=_rank, name='rank', arity=1)\n",
    "scale = make_function(function=_scale, name='scale', arity=1)\n",
    "sma = make_function(function=_sma, name='sma', arity=1)\n",
    "stddev = make_function(function=_stddev, name='stddev', arity=1)\n",
    "product = make_function(function=_product, name='product', arity=1)\n",
    "ts_rank = make_function(function=_ts_rank, name='ts_rank', arity=1)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=1)\n",
    "ts_max = make_function(function=_ts_max, name='ts_max', arity=1)\n",
    "ts_argmax = make_function(function=_ts_argmax, name='ts_argmax', arity=1)\n",
    "ts_argmin = make_function(function=_ts_argmin, name='ts_argmin', arity=1)\n",
    "ts_sum = make_function(function=_ts_sum, name='ts_sum', arity=1)\n",
    "\n",
    "cube = make_function(function=_cube, name='cube', arity=1)\n",
    "square = make_function(function=_square, name='square', arity=1)\n",
    "# stddev = make_function(function=_stddev, name='stddev', arity=2)\n",
    "\n",
    "corr = make_function(function=_corr, name='corr', arity=3)#     \n",
    "\n",
    "user_function = [delta, delay, rank, scale, sma,\n",
    "                stddev, product, ts_rank, ts_min,\n",
    "                ts_max, ts_argmax, ts_argmin, ts_sum,\n",
    "                cube, square, stddev, corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = 3\n",
    "function_set = init_function + user_function\n",
    "#metric = my_metric\n",
    "init_depth=(1,3) #最初生成树的深度(min_depth, max_depth)\n",
    "population_size = 100\n",
    "random_state=0\n",
    "tournament_size=20\n",
    "est_gp = SymbolicTransformer(\n",
    "                            feature_names=fields, \n",
    "                            function_set=function_set,\n",
    "                            generations=generations,\n",
    "                            metric='spearman',   #'spearman'秩相关系数\n",
    "                            parsimony_coefficient=0.001,#惩罚 节俭系数(越大,约束越强,默认0.001)\n",
    "                            init_depth=init_depth, # 公式树的初始化深度\n",
    "                            population_size=population_size,\n",
    "                            tournament_size= tournament_size, \n",
    "                            random_state=random_state,\n",
    "                            p_crossover = 0.4,\n",
    "                            p_subtree_mutation = 0.01,\n",
    "                            p_hoist_mutation = 0,\n",
    "                            p_point_mutation = 0.01,\n",
    "                            p_point_replace = 0.4,\n",
    "                         )\n",
    "\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取较优的表达式\n",
    "\n",
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness',ascending=False)\n",
    "best_programs_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将模型保存到本地\n",
    "with open('gp_multi_model.pkl', 'wb') as f:\n",
    "    pickle.dump(est_gp, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
