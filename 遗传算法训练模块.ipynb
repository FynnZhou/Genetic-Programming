{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:100: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:94: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:131: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "D:\\ruanjian\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:137: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata \n",
    "import pickle\n",
    "\n",
    "from gplearn import genetic\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicTransformer, SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('/data/train_data_pre3.pkl', 'rb') as train_f:\n",
    "    train_data = pickle.load(train_f)\n",
    "# with open('/home/kesci/test_total_data.pkl', 'rb') as test_f:\n",
    "#     test_data = pickle.load(test_f)\n",
    "\n",
    "fields = ['open', 'high', 'low', 'avg', 'pre_close', 'close','volume']\n",
    "# è®­ç»ƒæ•°æ®\n",
    "X_train = train_data[fields].values\n",
    "y_train = train_data['predict_pct'].values\n",
    "# # æµ‹è¯•æ•°æ®\n",
    "# X_test = test_data[fields].values\n",
    "# y_test = test_data['predict_pct'].values\n",
    "\n",
    "# ç³»ç»Ÿè‡ªå¸¦çš„å‡½æ•°ç¾¤\n",
    "\n",
    "\"\"\"\n",
    "Available individual functions are:\n",
    "\n",
    "â€˜addâ€™ : addition, arity=2.\n",
    "â€˜subâ€™ : subtraction, arity=2.\n",
    "â€˜mulâ€™ : multiplication, arity=2.\n",
    "â€˜divâ€™ : protected division where a denominator near-zero returns 1., arity=2.\n",
    "â€˜sqrtâ€™ : protected square root where the absolute value of the argument is used, arity=1.\n",
    "â€˜logâ€™ : protected log where the absolute value of the argument is used and a near-zero argument returns 0., arity=1.\n",
    "â€˜absâ€™ : absolute value, arity=1.\n",
    "â€˜negâ€™ : negative, arity=1.\n",
    "â€˜invâ€™ : protected inverse where a near-zero argument returns 0., arity=1. \n",
    "â€˜maxâ€™ : maximum, arity=2.\n",
    "â€˜minâ€™ : minimum, arity=2.\n",
    "â€˜sinâ€™ : sine (radians), arity=1.\n",
    "â€˜cosâ€™ : cosine (radians), arity=1.\n",
    "â€˜tanâ€™ : tangent (radians), arity=1.\n",
    "\"\"\"\n",
    "\n",
    "# init_function = ['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv', 'max', 'min', 'sin', 'cos', 'tan']\n",
    "init_function = ['add', 'sub', 'mul', 'div','sqrt', 'log','inv','sin','max','min']\n",
    "\n",
    "# è‡ªå®šä¹‰å‡½æ•°, make_functionå‡½æ•°ç¾¤\n",
    "\n",
    "def _rolling_rank(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºğ‘‹ğ‘–åœ¨å‘é‡ X ä¸­çš„åˆ†ä½æ•°\n",
    "    value = rankdata(data)[-1]\n",
    "    return value  #scipy.rankdata æ’åº\n",
    "\n",
    "def _rolling_prod(data):\n",
    "    return np.prod(data) #æ‰€æœ‰å…ƒç´ ä¹˜ç§¯\n",
    "\n",
    "\n",
    "def _delta(data):\n",
    "    value = np.diff(data.flatten())\n",
    "    value = np.append(0, value)\n",
    "    return value\n",
    "\n",
    "def _delay(data): # d å¤©ä»¥å‰çš„ X å€¼\n",
    "    period=1  #å½“periodä¸ºæ­£æ—¶ï¼Œé»˜è®¤æ˜¯axis = 0è½´çš„è®¾å®šï¼Œå‘ä¸‹ç§»åŠ¨\n",
    "    value = pd.Series(data.flatten()).shift(period)\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_sum(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¹‹å’Œ \n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).sum().tolist())  \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "    #a.flatten  æŠŠaé™åˆ°ä¸€ç»´ï¼Œé»˜è®¤æ˜¯æŒ‰æ¨ªçš„æ–¹å‘é™\n",
    "    #pandas.rolling(window) ä»¥çª—å£å–ç›¸é‚»æ•°æ®è¿›è¡Œè®¡ç®—\n",
    "    \n",
    "def _sma(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¹‹å¹³å‡å€¼\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).mean().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _stddev(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¹‹æ ‡å‡†å·®\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_rank(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¹‹ åˆ†ä½æ•°\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(10).apply(_rolling_rank).tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _product(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¹‹ ä¹˜ç§¯\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(10).apply(_rolling_prod).tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_min(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¸­æœ€å°å€¼\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).min().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_max(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¸­æœ€å¤§å€¼\n",
    "    window=10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).max().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def _rank(data): \n",
    "    value = np.array(pd.Series(data.flatten()).rank().tolist())  #pandas.rank å¹³å‡æ’ä½\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _scale(data): #scale(X, a) å‘é‡ a*X/sum(abs(X))ï¼Œa çš„ç¼ºçœå€¼ä¸º 1ï¼Œä¸€èˆ¬ a åº”ä¸ºæ­£æ•°\n",
    "    k=1\n",
    "    data = pd.Series(data.flatten())\n",
    "    value = data.mul(1).div(np.abs(data).sum()) \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_argmax(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¸­æœ€å¤§å€¼å‡ºç°çš„ä½ç½®\n",
    "    window=10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmax) + 1 \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "def _ts_argmin(data): #ç¬¬ i ä¸ªå…ƒç´ ä¸ºè¿‡å» d å¤©ğ‘‹ğ‘–å€¼æ„æˆçš„æ—¶åºæ•°åˆ—ä¸­æœ€å°å€¼å‡ºç°çš„ä½ç½®\n",
    "    window=10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmin) + 1 \n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "##########################################    \n",
    "def _cube(data):\n",
    "    return np.square(data)*data\n",
    "\n",
    "def _square(data):\n",
    "    return np.square(data)\n",
    "    \n",
    "def _corr(data1,data2,n):\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "            \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window  = n[0]\n",
    "\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "            \n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "            \n",
    "# def _stddev(data,n):   \n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "#         try:    \n",
    "#             if n[0] == n[1] and n[1] ==n[2]:\n",
    "#                 window  = int(np.mean(n))\n",
    "                \n",
    "#                 value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "#                 value = np.nan_to_num(value)\n",
    "    \n",
    "#                 return value\n",
    "#             else:\n",
    "#                 return np.zeros(data.shape[0])\n",
    "                \n",
    "#         except:\n",
    "#             return np.zeros(data.shape[0])\n",
    "\n",
    "# make_functionå‡½æ•°ç¾¤\n",
    "delta = make_function(function=_delta, name='delta', arity=1)\n",
    "delay = make_function(function=_delay, name='delay', arity=1)\n",
    "rank = make_function(function=_rank, name='rank', arity=1)\n",
    "scale = make_function(function=_scale, name='scale', arity=1)\n",
    "sma = make_function(function=_sma, name='sma', arity=1)\n",
    "stddev = make_function(function=_stddev, name='stddev', arity=1)\n",
    "product = make_function(function=_product, name='product', arity=1)\n",
    "ts_rank = make_function(function=_ts_rank, name='ts_rank', arity=1)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=1)\n",
    "ts_max = make_function(function=_ts_max, name='ts_max', arity=1)\n",
    "ts_argmax = make_function(function=_ts_argmax, name='ts_argmax', arity=1)\n",
    "ts_argmin = make_function(function=_ts_argmin, name='ts_argmin', arity=1)\n",
    "ts_sum = make_function(function=_ts_sum, name='ts_sum', arity=1)\n",
    "\n",
    "cube = make_function(function=_cube, name='cube', arity=1)\n",
    "square = make_function(function=_square, name='square', arity=1)\n",
    "# stddev = make_function(function=_stddev, name='stddev', arity=2)\n",
    "\n",
    "corr = make_function(function=_corr, name='corr', arity=3)#     \n",
    "\n",
    "user_function = [delta, delay, rank, scale, sma,\n",
    "                stddev, product, ts_rank, ts_min,\n",
    "                ts_max, ts_argmax, ts_argmin, ts_sum,\n",
    "                cube, square, stddev, corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = 3\n",
    "function_set = init_function + user_function\n",
    "#metric = my_metric\n",
    "init_depth=(1,3) #æœ€åˆç”Ÿæˆæ ‘çš„æ·±åº¦(min_depth, max_depth)\n",
    "population_size = 100\n",
    "random_state=0\n",
    "tournament_size=20\n",
    "est_gp = SymbolicTransformer(\n",
    "                            feature_names=fields, \n",
    "                            function_set=function_set,\n",
    "                            generations=generations,\n",
    "                            metric='spearman',   #'spearman'ç§©ç›¸å…³ç³»æ•°\n",
    "                            parsimony_coefficient=0.001,#æƒ©ç½š èŠ‚ä¿­ç³»æ•°(è¶Šå¤§,çº¦æŸè¶Šå¼º,é»˜è®¤0.001)\n",
    "                            init_depth=init_depth, # å…¬å¼æ ‘çš„åˆå§‹åŒ–æ·±åº¦\n",
    "                            population_size=population_size,\n",
    "                            tournament_size= tournament_size, \n",
    "                            random_state=random_state,\n",
    "                            p_crossover = 0.4,\n",
    "                            p_subtree_mutation = 0.01,\n",
    "                            p_hoist_mutation = 0,\n",
    "                            p_point_mutation = 0.01,\n",
    "                            p_point_replace = 0.4,\n",
    "                         )\n",
    "\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–è¾ƒä¼˜çš„è¡¨è¾¾å¼\n",
    "\n",
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness',ascending=False)\n",
    "best_programs_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # å°†æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°\n",
    "with open('gp_multi_model.pkl', 'wb') as f:\n",
    "    pickle.dump(est_gp, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
